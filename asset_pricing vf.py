# -*- coding: utf-8 -*-
"""Asset Pricing

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l9qy9-Ht9AnXUziFEcZG3PG00ZJ0KUr_

Importation des packages
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
import os
import yfinance as yf
import seaborn as sns
import plotly.graph_objects as go
import statsmodels.api as sm
from statsmodels.tsa.stattools import adfuller
from scipy import stats
from statsmodels.graphics.tsaplots import plot_acf,plot_pacf
from statsmodels.stats.diagnostic import acorr_ljungbox

"""Dataset: This data set consists of monthly stock price, dividends, and earnings data and the consumer price index (to allow conversion to real values)-ROBERT SHILLER"""

data= pd.read_csv("/content/Dataset_AssetPricing(Data).csv", delimiter=';', decimal=",")

print(data.head())



cols_to_fix = ["P", "D", "E", "CPI", "Price", "Dividend"]
for col in cols_to_fix:
    if col in data.columns:
        data[col] = data[col].astype(str).str.replace(",", ".")
        data[col] = pd.to_numeric(data[col], errors="coerce")

dataset= data[["Year","Month","P", "D", "E", "CPI", "Price", "Dividend"]]

dataset = dataset.sort_values(["Year", "Month"]).reset_index(drop=True)

month_fixed = []
counter = 1

for i in range(len(dataset)):
    month_fixed.append(counter)
    counter += 1
    if counter > 12:
        counter = 1

dataset["Month_fixed"] = month_fixed

dataset["Month"] = dataset["Month_fixed"]
dataset = dataset.drop(columns=["Month_fixed"])
dataset['date'] = pd.to_datetime(dict(year=dataset.Year, month=dataset.Month,day=1))

print(dataset.head())

dataset = dataset.sort_values(["Year", "Month"]).reset_index(drop=True)

month_fixed = []
counter = 1

for i in range(len(dataset)):
    month_fixed.append(counter)
    counter += 1
    if counter > 12:
        counter = 1

dataset["Month_fixed"] = month_fixed

dataset["Month"] = dataset["Month_fixed"]
dataset = dataset.drop(columns=["Month_fixed"])

df = dataset[(dataset["date"] >= "2000-01-01") & (dataset["date"] <= "2025-12-31")].copy()
df2 = dataset[(dataset["date"] >= "1960-01-01") & (dataset["date"] <= "2025-12-31")].copy()

df = df.reset_index(drop=True)
df2 = df2.reset_index(drop=True)
df.head()

""" Informational Efficiency / Martingale Property"""

#returns creation
df["log_P"]=np.log(df["P"])

df = df.sort_values(by="date")

df["returns"] = df["log_P"].diff()

print("First Rows:")
print(df[["P", "log_P", "returns"]].head())

print("Last rows")
print(df[["P", "log_P", "returns"]].tail())

# --- Verificación estadística básica ---
print("Statistic info about returns:")
print(df["returns"].describe())

#graph returns
fig = go.Figure([go.Scatter(x=df['date'], y=df['returns'], line=dict(color='royalblue'))])
fig.update_layout(
    title="Monthly Returns of the S&P 500 (2020–2025)",
    xaxis_title="Date",
    yaxis_title="Log Returns",
    template="plotly_white"
)
fig.show()

#graph returns
fig = go.Figure([go.Scatter(x=df['date'], y=df['P'], line=dict(color='royalblue'))])
fig.update_layout(
    title="Monthly Prices of the S&P 500 (2020–2025)",
    xaxis_title="Date",
    yaxis_title="Level P",
    template="plotly_white"
)
fig.show()

# Plotting density of GOOGLE daily returns
sns.distplot(df['returns'], norm_hist=True, fit=stats.norm, color='blue', bins=50)
plt.tight_layout()
plt.show()

"""
 Informational Efficiency / Martingale Property

"""

ADF LOG P y returns

res1 = adfuller(df["log_P"].dropna(), autolag="AIC", regression="ct")

res2 = adfuller(df["returns"].dropna(), autolag="AIC", regression="c")

def to_row(name, res):
    stat, p, lags, nobs, crit, icbest = res
    return pd.Series({
        "series": name,
        "stat": stat, "pvalue": p, "lags": lags, "nobs": nobs,
        "cv_1%": crit["1%"], "cv_5%": crit["5%"], "cv_10%": crit["10%"]
    })

out = pd.concat([to_row("log_P (trend)", res1), to_row("returns", res2)], axis=1).T
print(out)

"""
Pvalue higher than 0.05 is not stationnary so:

The Augmented Dickey–Fuller test fails to reject the unit-root hypothesis for log prices (p = 0.31) but strongly rejects it for returns (p < 0.01).
This indicates that prices follow a random-walk process, while returns are stationary, consistent with weak-form informational efficiency."""

df['date'] = pd.to_numeric(pd.to_datetime(df['date']))

#Grapgh ACF and PACF
# ACF shows correlation with past values; PACF shows direct correlation at each lag after removing intermediate effects.

fig, axes = plt.subplots(1, 2, figsize=(12, 4))

# Autocorrelation Function
plot_acf(df["returns"].dropna(), lags=24, ax=axes[0])
axes[0].set_title("ACF of S&P 500 Returns (2020–2025)")
plot_pacf(df["returns"].dropna(), lags=24, ax=axes[1])
axes[1].set_title("PACF of Returns")
#The ACF of monthly S&P 500 returns from 2020 to 2025 shows no significant autocorrelation at any lag, with all bars within the 95% confidence bands.

s=pd.to_numeric(df["returns"], errors="coerce").dropna()
lb = acorr_ljungbox(s, lags=[6,12,24], return_df=True)
print(lb)
#p>0.05. No refuse H0, so no evidence of autocorreletion
#Monthly returns behave like white noise, consistent with weak-form E

"""First part conclusion: Prices follow a random walk and retorns act like white noise, ie, (no autocorrelation).

For the second part, will use PRICE AND DIVIDED, because they're real variables
"""

df2 = df2.dropna(subset=["Price", "Dividend"]).copy()
df2 = df2[df2["Dividend"] > 0].copy()
df2["log_P_real"]=np.log(df2["Price"])
df2["log_D_real"]=np.log(df2["Dividend"])
df2 = df2.sort_values(by="date")
df2=df2.copy()
df2["dp"] = df2["log_D_real"] - df2["log_P_real"]
df2.head()

adfP = adfuller(df2["log_P_real"].dropna(), autolag="AIC", regression="ct")
# returns (con constante)
adfD = adfuller(df2["log_D_real"].dropna(), autolag="AIC", regression="ct")
adfP_diff = adfuller(df2["log_P_real"].diff().dropna(), autolag="AIC", regression="c")
adfD_diff = adfuller(df2["log_D_real"].diff().dropna(), autolag="AIC", regression="c")

def to_row(name, res):
    stat, p, lags, nobs, crit, icbest = res
    return pd.Series({
        "series": name,
        "stat": stat, "pvalue": p, "lags": lags, "nobs": nobs,
        "cv_1%": crit["1%"], "cv_5%": crit["5%"], "cv_10%": crit["10%"]
    })

out = pd.concat([
    to_row("log_P_real (level, trend)", adfP),
    to_row("log_D_real (level, trend)", adfD),
    to_row("Δlog_P_real (diff, const)", adfP_diff),
    to_row("Δlog_D_real (diff, const)", adfD_diff)
], axis=1).T

print(out)

"""
Pvalue higher than 0.05 is not stationnary. No reject H0
For levels we reject so not stationnary but for the first differences, it is stationnary.
This indicates that both variables are integrated of order one, I(1)
"""

# estimation relation long run
X = sm.add_constant(df2["log_D_real"])
y = df2["log_P_real"]

model = sm.OLS(y, X)
results = model.fit()

print(results.summary())
#1.73 implies a strong positive long-run link between dividends and prices.

#If the resids are stationary (I(0)), it means prices and dividends are cointegrated
adf_resid = adfuller(results.resid, regression="n", autolag="AIC") #“n” : no constant, no trend. Because residuals  have mean close to 0
stat, pval, lags, nobs, crit, icbest = adf_resid
print("ADF(resid) stat:", stat, "p:", pval, "lags:", lags)
print("Crit values:", crit)
# p value<0.05 so we rejet H0. Resids are stationnary. We confirm cointegration

df2["u_hat"]     = results.resid         # residuo de la regresión de largo plazo: log_P_real ~ const + log_D_real
df2["u_hat_lag"] = df2["u_hat"].shift(1)
df2["dlogP"]     = df2["log_P_real"].diff()
df2["dlogD"]     = df2["log_D_real"].diff()

#We estimated an error-correction model (ECM) for real price changes, linking Δlog P to the lagged cointegration error and short-run dividend growth, with HAC standard errors.
k = 2
for i in range(1, k+1):
    df2[f"dlogP_lag{i}"] = df2["dlogP"].shift(i)
    df2[f"dlogD_lag{i}"] = df2["dlogD"].shift(i)

y = df2["dlogP"]
X_cols = ["u_hat_lag", "dlogD"] + [f"dlogP_lag{i}" for i in range(1, k+1)] + [f"dlogD_lag{i}" for i in range(1, k+1)]
X = sm.add_constant(df2[X_cols])

ecm_df = pd.concat([y, X], axis=1).dropna()
y_ecm = ecm_df["dlogP"]
X_ecm = ecm_df.drop(columns=["dlogP"])

# OLS with HAC (Newey–West). Banda 12 meses (conservadora en mensual)
ecm_res = sm.OLS(y_ecm, X_ecm).fit(cov_type="HAC", cov_kwds={"maxlags": 12})
print(ecm_res.summary().tables[1])

phi = ecm_res.params["u_hat_lag"]
print(f"\nError-correction (phi) = {phi:.4f}  --> expected < 0 if adjustment to the equilibrium")

"""The model suggests that only about 1.2% of a deviation from equilibrium is corrected each month
Monthly shocks tend to partially reverse over the next 1–2 months once you control for the long-run equilibrium, month-to-month dividend growth doesn’t add explanatory power for price changes.
"""

print("dp in columns?", "dp" in df2.columns)
print(df2[["log_D_real","log_P_real","dp"]].head())

# Campbell to prove if dp=log d real-log p real really predict futurs returns

# Real return 1 month
df2["r1_real"] = df2["log_P_real"].diff().shift(-1) #r1_real is the next-month real price return

# Total Real return aprox.: Δlog P + log(1+DY)
df2["dy_real"] = df2["Dividend"] / df2["Price"] #Builds the dividend yield
df2["r1_total_real"] = df2["log_P_real"].diff().shift(-1) + np.log1p(df2["dy_real"])

def cs_reg(ycol, xcol="dp", maxlags=12, label=""):
    tmp = df2[[ycol, xcol]].dropna()
    y = tmp[ycol]; X = sm.add_constant(tmp[xcol])
    res = sm.OLS(y, X).fit(cov_type="HAC", cov_kwds={"maxlags": maxlags})
    print(f"\n=== Campbell–Shiller {label} ===")
    print(res.summary().tables[1])
    print(f"beta(dp) = {res.params[xcol]:.4f}, R2 = {res.rsquared:.4f}")
    return res

res_cs_p = cs_reg("r1_real", label="(real price return, 1m)") #Runs the regression twice: once for price-only returns
res_cs_tot = cs_reg("r1_total_real", label="(real total return, 1m)") # once for total (price + dividend yield).

"""Results: dp 0.008 POSITIVE, when dp is high (market “cheap”), next-month price returns tend to be higher.
For total return dp 0.0345 POSITIVE, higher dp_total robustly predicts higher next-month total returns.
Including the dividend yield in the dependent variable lines up better with the valuation logic: when dp is high,
 part of the next return mechanically comes from a higher yield and the rest from expected price appreciation.

paper: The dividend-price ratio is high when prices are low, and the effect on returns implies that prices rises subsequently
"""







